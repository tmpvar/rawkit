// Copy the depth attachment from the rendered frame into the
// base of the depth pyramid
// originally from: https://github.com/sebbbi/rust_test
#version 450
layout (local_size_x = 8, local_size_y = 8) in;

#include "../shared.h"

layout(binding = 0) uniform DepthPyramidUBO {
  DepthPyramidConstants depth_pyramid;
} push;

layout (binding = 1) uniform sampler2D src_tex;
layout (binding = 2, r32f) uniform writeonly image2D dst_tex;

coherent layout (binding = 2, r32f) uniform image2D tex;
coherent layout (binding = 3, r32ui) uniform uimage2D counters;	// NxN/8x8 texels (one level)
shared uint counter_return;

uvec4 calculate_mip_rect(uint dimensions, uint mip) {
  uint pixels_mip = dimensions >> mip;
  uvec4 uv_rect = uvec4(0, 0, pixels_mip, pixels_mip);
  if (mip > 0) {
      uv_rect.x = dimensions;
      uv_rect.y = dimensions - pixels_mip * 2;
  }
  return uv_rect;
}

void main() {
    uvec2 xy_group = uvec2(gl_WorkGroupID.xy);
    uvec2 xy_local = uvec2(gl_LocalInvocationID.xy);

    for (uint mip = 0; mip < push.depth_pyramid.mip; mip++) {
        uvec2 xy = xy_group * 8 + xy_local;

        uvec4 src_rect = calculate_mip_rect(push.depth_pyramid.diameter, mip);
        uvec4 dst_rect = calculate_mip_rect(push.depth_pyramid.diameter, mip + 1);

        // Could use image gather instead of 4 loads...
        uvec2 xy2 = 2 * xy;
        float z00 = imageLoad(tex, ivec2(src_rect.xy + xy2 + uvec2(0, 0))).x;
        float z01 = imageLoad(tex, ivec2(src_rect.xy + xy2 + uvec2(0, 1))).x;
        float z10 = imageLoad(tex, ivec2(src_rect.xy + xy2 + uvec2(1, 0))).x;
        float z11 = imageLoad(tex, ivec2(src_rect.xy + xy2 + uvec2(1, 1))).x;

        float z_min = min(min(z00, z01), min(z10, z11));
        imageStore(tex, ivec2(dst_rect.xy + xy), vec4(z_min,0.0,0.0,0.0));

        // Barrier + coherent attribute guarantee that other thread groups see the data
        memoryBarrierBuffer();

        // There are 2x2 groups that are candidates for downsampling the same 2x2 lower resolution region
        // We take the last one to finish, since this guarantees that the next level input data is finished
        xy_group /= 2;

        // First lane in group does the atomic increment
        // We bitpack sixteen 2 bit counters to a single 32 bit counter to avoid clearing the counter (double barrier)
        if (xy_local == uvec2(0,0))
        {
        	counter_return = imageAtomicAdd(counters, ivec2(xy_group), 1 << (mip*2));
        }

        // For each 2x2 group tile, the last one to finish lives to the next mip level. Other 3 die.
        // This branch is guaranteed to kill the whole group, as it's based on groupshared value
        if (((counter_return >> (mip*2)) & 3) < 3) return;
    }
}